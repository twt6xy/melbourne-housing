---
title: "Melbourne Analysis"
author: "Timothy Tyree"
date: "4/24/2021"
output:
  html_document:
    df_print: paged
  pdf_document: default
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)

library(tidyverse) 
library(broom) # augment and tidy
library(knitr) # kable
library(lubridate) # Datetime
library(plotly)
library(heatmaply)
library(ggcorrplot)
```
```{r}
melbourne <- read.csv("melbourne_cleaned.csv", header=TRUE)
melbourne = subset(melbourne, select = -c(X) )
melbourne$YearBuilt<-round(as.numeric(melbourne$YearBuilt), 0)

# ==============================================================================
# The dataset contains multiple categorical variables, so create a list of them
# and tell R to turn them into a factor
# ==============================================================================

cats <- c('Type', 'Regionname', 'Postcode', 'CouncilArea', 'Suburb', 'Year', 'Month')
melbourne$Population <- as.numeric(gsub(",","",melbourne$Population))
melbourne[,cats] <- lapply(melbourne[,cats], factor)
```

### Visualizing the Numeric Correlations, Point Size Changes According to Correlation Test p-values
```{r}
numericVals <- subset(melbourne, select=-c(SellerG, Method, Suburb, Date, Postcode, CouncilArea, Lattitude, Longtitude, Regionname, Type, Year, Month))

# Compute correlation coefficients
cor.coef <- cor(numericVals)

# Compute correlation p-values
cor.test.p <- function(x){
    FUN <- function(x, y) cor.test(x, y)[["p.value"]]
    z <- outer(
      colnames(x), 
      colnames(x), 
      Vectorize(function(i,j) FUN(x[,i], x[,j]))
    )
    dimnames(z) <- list(colnames(x), colnames(x))
    z
}

p <- cor.test.p(numericVals)

heatmaply_cor(
  cor.coef,
  node_type = "scatter",
  point_size_mat = -log(p), 
  point_size_name = "-log10(p-value)",
  label_names = c("x", "y", "Correlation")
)
```
* Bedroom2 is just the number of bedrooms scraped from another source so we need to drop that due to multicollinearity

### Melbourne Price Density Map
```{r}
fig <- melbourne 
fig <- fig %>%
  plot_ly(
    type = 'densitymapbox',
    lat = ~Lattitude,
    lon = ~Longtitude,
    coloraxis = 'Price',
    radius = 10,
    opacity = 0.5,
    zoom = 13
    ) 
fig <- fig %>%
  layout(
    mapbox = list(
      style="stamen-terrain",
      zoom = 10,
      center= list(lat=-37.8, lon=145)),
      coloraxis = list(colorscale = "Viridis"))

fig
```
* Melbourne housing prices are high in most areas. We may not need to worry about all the suburbs.

### All Price Distributions
```{r}
pl <- plot_ly(y=~melbourne$Price,
              type="box")
pl
```


### Region Names
```{r}
p <- plot_ly(melbourne, x = ~Regionname, y = ~Price, color = ~Regionname, type = "box")
p <- p %>% layout(boxmode = "group")
p
```
  
```{r}
region_classes <- melbourne %>% group_by(Regionname) %>% summarize(mean_price = round(mean(Price),2))
ggplot(region_classes, aes(x=Regionname, y=mean_price, fill=Regionname)) +
  geom_bar(stat = "identity", width = 0.5) +
  geom_text(aes(label = mean_price), hjust = .5,
            color = "white",
            size = 3) + 
  theme_classic()
```
* Regions don't seem different enough in their mean prices to help a model estimate house price accurately

### Building Type
```{r}
t <- plot_ly(melbourne, x = ~Type, y = ~Price, color = ~Type, type = "box")
t <- t %>% layout(boxmode = "group")
t
```


### Landsize Distribution
```{r}
fig <- plot_ly(y = melbourne$Landsize, type = "box")
fig
```
* Definitely an outlier there

### Distance and Price
```{r}
fig <- plot_ly(x = ~melbourne$Distance, y = ~melbourne$Price, type = 'box')
fig
```

```{r}
fig <- plot_ly(x = ~melbourne$Date, y = ~melbourne$Price, mode = 'lines')
fig
```


### Creating Models
```{r}
pricingModel <- lm(Price~Month+Year+Landsize+Rooms+Distance+Bathroom+Car+BuildingArea+YearBuilt+CouncilArea+Propertycount+Walk.Score+Population, data=melbourne)
summary(pricingModel)
```


### Check for Autocorrelation
```{r}
res<-pricingModel$residuals

##PACF plot of residuals
pacf(res, main="PACF of Residuals")
```
* There is autocorrelation in the residuals  
```{r}

```

### Checking For Multicollinearity in the Baseline Model
```{r}
library(faraway)
vif(pricingModel)
```
* No multicollinearity issues in the baseline model

## Dealing With Outlier  
```{r}
cooksd <- cooks.distance(pricingModel)
plot(cooksd, pch="*", cex=2, main="Influential Observations by Cooks distance")  # plot cook's distance
abline(h = 4*mean(cooksd, na.rm=T), col="red")  # add cutoff line
text(x=1:length(cooksd)+1, y=cooksd, labels=ifelse(cooksd>4*mean(cooksd, na.rm=T),names(cooksd),""), col="red")  # add labels
```
* Observation 13156: 71 Hamilton Rd, New Gisborne VIC 3438, Australia
* This observation is a ranch about 50 miles outside of Melbourne. Building area = 44515.00, land size = 44500. Both variables far greater than the average. 
* We should delete this from the dataset since we're concerned with predicting houses actually in Melbourne.  

* Observation 13832: 389 Gore St Fitzroy VIC 3065, Australia
* The data says the land size is 433014, looking the address up on google maps confirms that this is undoubtedly a data entry error. This property is a row house in close proximity to downtown Melbourne.
* Land size is actuall 107, https://www.onthehouse.com.au/property/vic/fitzroy-3065/389-gore-st-fitzroy-vic-3065-7029467

* Observation 10257: 5 Armstrong St, Middle Park VIC 3206, Australia
* Data entry error where the year says it was built in 1196
* Year built is 1960, https://www.propertyvalue.com.au/property/5-armstrong-street-mount-waverley-vic-3149/12065558  

* THE TEXT ABOVE IS AN EXAMPLE OF FINDING INCORRECT INFORMATION WITHIN THE DATASET. THERE WERE TOO MANY INSTANCES OF DATA ENTRY ERRORS, WHICH WE CAN PROVE, BUT RATHER THAN SHOWING ALL OF THAT IN THIS NOTEBOOK, WE ARE GOING TO FILTER OUT BUILDING AREA AND LANDSIZE GREATER THAN THEIR RESPECTIVE 98TH PERCENTILE.

```{r}
quantile(melbourne$Landsize, probs = c(.25, .5, .75))
```
```{r}
quantile(melbourne$Landsize, probs = c(.98))
```
* 994 $m^2$ seems fair for a cutoff land size value. There are values in the dataset in the 10s of thousand which are obviously not correct.  

```{r}
quantile(melbourne$BuildingArea, probs = c(.25, .5, .75))
```
```{r}
quantile(melbourne$BuildingArea, probs = c(.95))
```
```{r}
quantile(melbourne$BuildingArea, probs = c(.99))
```
* Very indicative of how influential the building size data entry errors are. 

```{r}
melbourneMassiveOutliersRemoved <- melbourne[!melbourne$BuildingArea > quantile(melbourne$BuildingArea, probs = c(.98)),]
melbourneMassiveOutliersRemoved <- melbourneMassiveOutliersRemoved[!melbourneMassiveOutliersRemoved$Landsize > quantile(melbourne$Landsize, probs = c(.98)),]
```

## Fitting an Outlier Corrected Model
```{r}
pricingModelOutlierCorrected <- lm(Price~Month+Year+Landsize+Rooms+Distance+Bathroom+Car+BuildingArea+YearBuilt+CouncilArea+Propertycount, data=melbourneMassiveOutliersRemoved)
summary(pricingModelOutlierCorrected)
```

## Checking for Influential Observations Again  
```{r}
cooksd2 <- cooks.distance(pricingModelOutlierCorrected)
plot(cooksd2, pch="*", cex=2, main="Influential Observations by Cooks distance")  # plot cook's distance
abline(h = 4*mean(cooksd2, na.rm=T), col="red")  # add cutoff line
text(x=1:length(cooksd2)+1, y=cooksd2, labels=ifelse(cooksd2>4*mean(cooksd2, na.rm=T),names(cooksd2),""), col="red")  # add labels
```
* The remaining outliers seem to be apartment units with landsize zero, or houses with a large, but realistic (likely exurbs), amount of land.  

```{r}
fig <- plot_ly(y = melbourneMassiveOutliersRemoved$Landsize, type = "box")
fig
```


```{r}
fig <- plot_ly(y = melbourneMassiveOutliersRemoved$BuildingArea, type = "box")
fig
```
### Transforms, PCA, Etc.











