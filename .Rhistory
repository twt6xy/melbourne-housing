install.packages('tidyverse')
library(tidyverse)
install.packages(c("nycflights13", "gapminder", "Lahman"))
1+2
mpg
ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy))
ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy, color = class))
# Right
ggplot(data = mpg) +
geom_point(mapping = aes(x = displ, y = hwy, shape = class))
# Right
ggplot(data = mpg) +
geom_point(mapping = aes(x = displ, y = hwy, shape = class))
ggplot(data = mpg) +
geom_point(mapping = aes(x = displ, y = hwy), color = "blue")
ggplot(data = mpg) +
geom_point(mapping = aes(x = displ, y = hwy)) +
facet_wrap(~ class, nrow = 2)
ggplot(data = mpg) +
geom_point(mapping = aes(x = displ, y = hwy)) +
facet_grid(drv ~ cyl)
ggplot(data = mpg) +
geom_point(mapping = aes(x = displ, y = hwy)) +
facet_grid(drv ~ .)
ggplot(data = mpg) +
geom_point(mapping = aes(x = displ, y = hwy)) +
facet_grid(. ~ cyl)
ggplot(data = mpg) +
geom_point(mapping = aes(x = displ, y = hwy)) +
facet_wrap(~ class, nrow = 2)
ggplot(data = mpg) +
geom_point(mapping = aes(x = displ, y = hwy)) +
facet_wrap(~ class, nrow = 3)
# left
ggplot(data = mpg) +
geom_point(mapping = aes(x = displ, y = hwy))
# left
ggplot(data = mpg) +
geom_smooth(mapping = aes(x = displ, y = hwy))
# left
ggplot(data = mpg) +
geom_smooth(mapping = aes(x = displ, y = hwy, linetype = drv))
# left
ggplot(data = mpg) +
geom_smooth(mapping = aes(x = displ, y = hwy, linetype = drv, color = drv))
# left
ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) +
geom_point(mapping = aes(color = class)) +
geom_smooth()
# left
ggplot(data = mpg, mapping = aes(x = displ, y = hwy, color = drv)) +
geom_point() +
geom_smooth(se = FALSE)
# left
ggplot(data = mpg, mapping = aes(x = displ, y = hwy, color = drv)) +
geom_point() +
geom_smooth()
# left
ggplot(data = diamonds) +
geom_bar(mapping = aes(x = cut))
# left
ggplot(data = diamonds) +
stat_summary(
mapping = aes(x = cut, y = depth),
fun.min = min,
fun.max = max,
fun = median
)
# left
ggplot(data = diamonds) +
geom_bar(mapping = aes(x = cut, colour = cut))
ggplot(data = diamonds) +
geom_bar(mapping = aes(x = cut, fill = cut))
ggplot(data = diamonds) +
geom_bar(mapping = aes(x = cut, fill = clarity))
ggplot(data = diamonds) +
geom_bar(mapping = aes(x = cut, fill = clarity), position = "fill")
ggplot(data = diamonds) +
geom_bar(mapping = aes(x = cut, fill = clarity), position = "dodge")
nz <- map_data("nz")
bar + coord_polar()
x
x
x <- 3*4
x
include(tidyverse)
library(tidyverse)
pnorm(0.223)
pnorm(0.3301)
qnorm(0.975)
qt(0.95, 10)
x <- 76.7
s <- 12.3
ci <- .95
a <- 1-a/2
k <- 109
n <- 110
Cu <- x + qt(a,k)*s/sqrt(n)
Cl <- x - qt(a,k)*s/sqrt(n)
x <- 76.7
s <- 12.3
ci <- .95
a <- 1-ci/2
k <- 109
n <- 110
Cu <- x + qt(a,k)*s/sqrt(n)
Cl <- x - qt(a,k)*s/sqrt(n)
x <- 76.7
s <- 12.3
ci <- .95
a <- 1-0.95
k <- 109
n <- 110
Cu <- x + qt(1-a/2,k)*s/sqrt(n)
Cl <- x - qt(1-a/2,k)*s/sqrt(n)
pnorm(.41667)
1-pnotm(.4167)
1-pnorm(.4167)
1-pnorm(2.771)
1-pnorm(.7217)
qt(0.97,48)
qt(.93,81)
qt(0.87,149)
x <- 3.2
n <- 100
s <- 0.2
a <- 1-0.97
df <- 100-1
right <- x + qt(1-a/2, df)*s/sqrt(n)
left <- x - qt(1-a/2, df)*s/sqrt(n)
qt(1-a/2, df)*s/sqrt(n)
qt(1-a/2, df)*s/sqrt(n)
qt(1-0.05/(2*3), 200-3-1)
library(glmnet)
##model.matrix automatically transform categorical variables into dummy codes, which is needed as the glmnet function cannot handle categorical variables
x<-model.matrix(mpg~.,mtcars)[,-1]
y<-mtcars$mpg
View(x)
pairs(x, lower.panel=NULL, main="Scatterplots of Predictors")
##alpha=0 for ridge, alpha=1 for LASSO
##threshold value should be very small if multicollinearity is present. see what happens if thresh was set to a larger value
##we know theoretically the coeffs should be the same as lm when lambda is 0
ridge.r<-glmnet(x,y,alpha=0, lambda=0, thresh = 1e-14)
coefficients(ridge.r)
##MLR
result<-lm(mpg~.,mtcars)
summary(result)
ridge.r<-glmnet(x,y,alpha=0, lambda=0, thresh = 1e-14)
coefficients(ridge.r)
##alpha=0 for ridge, alpha=1 for LASSO
##threshold value should be very small if multicollinearity is present. see what happens if thresh was set to a larger value
##we know theoretically the coeffs should be the same as lm when lambda is 0
ridge.r<-glmnet(x,y,alpha=0, lambda=0, thresh = 1e-4)
ridge.r<-glmnet(x,y,alpha=0, lambda=0, thresh = 1e-4)
coefficients(ridge.r)
x<-model.matrix(mpg~.,mtcars)[,-1]
y<-mtcars$mpg
##Note some predictors are highly correlated with each other.
pairs(x, lower.panel=NULL, main="Scatterplots of Predictors")
##alpha=0 for ridge, alpha=1 for LASSO
##threshold value should be very small if multicollinearity is present. see what happens if thresh was set to a larger value
##we know theoretically the coeffs should be the same as lm when lambda is 0
ridge.r<-glmnet(x,y,alpha=0, lambda=0, thresh = 1e-14)
coefficients(ridge.r)
result<-lm(mpg~.,mtcars)
summary(result)
set.seed(12)
train<-sample(1:nrow(x), nrow(x)/2)
test<-(-train)
y.test<-y[test]
set.seed(12)
cv.out<-cv.glmnet(x[train,],y[train],alpha=0)
bestlam<-cv.out$lambda.min
bestlam
plot(cv.out)
ridge.mod<-glmnet(x[train,],y[train],alpha=0,lambda=bestlam, thresh = 1e-14)
ridge.pred<-predict(ridge.mod,s=bestlam,newx=x[test,])
mean((ridge.pred-y.test)^2)
ridge.mod.0<-glmnet(x[train,],y[train],alpha=0,lambda=0, thresh = 1e-14)
ridge.pred.0<-predict(ridge.mod.0,newx=x[test,])
mean((ridge.pred.0-y.test)^2)
out.ridge<-glmnet(x,y,alpha=0,lambda=bestlam,thresh = 1e-14)
out.ols<-glmnet(x,y,alpha=0, lambda=0, thresh = 1e-14)
cbind(coefficients(out.ridge), coefficients(out.ols))
grid<-10^seq(10,-2,length=100)
out.all<-glmnet(x,y,alpha=0,lambda=grid,thresh = 1e-14)
plot(out.all, xvar = "lambda")
abline(v=log(bestlam), lty=2)
legend("bottomright", lwd = 1, col = 1:6, legend = colnames(x), cex = .7)
names(mtcars)
?mtcars
pr.out<-prcomp(mtcars[,c(-8,-9)], scale=TRUE)
pr.out$center
pr.out$scale
apply(mtcars[,c(-8,-9)], 2, mean)
apply(mtcars[,c(-8,-9)], 2, sd)
pr.out$rotation
pr.out$sdev
pr.var<-pr.out$sdev^2
pr.var
pve<-pr.var/sum(pr.var)
pve
biplot(pr.out, scale=0)
plot(pve, ylim=c(0,1))
plot(pve, xlab="Principal Component", ylab="Proportion of Variance Explained", main="Scree Plot", ylim=c(0,1),type='b')
plot(cumsum(pve), xlab="Principal Component", ylab="Cumulative Proportion of Variance Explained", main="Cumulative Proportion", ylim=c(0,1),type='b')
names(mtcars)
?mtcars
x<-model.matrix(mpg~.,mtcars)[,-1]
y<-mtcars$mpg
setwd("~/MSDS/Spring 2021/Linear Models For Data Science/melbourne-housing")
shiny::runApp()
runApp()
install.packages("aplpack")
runApp()
