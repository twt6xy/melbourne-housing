<<<<<<< HEAD
shiny::runApp('C:/Users/MSachs.MSACHS-DELL/Downloads')
shiny::runApp('UVA MSDS/STAT 6021/melbourne-housing')
runApp('UVA MSDS/STAT 6021/melbourne-housing')
runApp('UVA MSDS/STAT 6021/melbourne-housing')
runApp('UVA MSDS/STAT 6021/melbourne-housing')
setwd(dir = "C:/Users/MSachs.MSACHS-DELL/Documents/UVA MSDS/STAT 6021/melbourne-housing")
melb.df <- read.csv("melbourne_cleaned.csv", stringsAsFactors = FALSE, na.strings = c(""," ","NA"))
View(melb.df)
runApp()
runApp()
runApp()
runApp()
runApp()
!(Price %in% c("Price","Rooms","Bathroom","Distance","Car","Landsize","BuildingArea","YearBuilt")
)
=======
x
include(tidyverse)
library(tidyverse)
pnorm(0.223)
pnorm(0.3301)
qnorm(0.975)
qt(0.95, 10)
x <- 76.7
s <- 12.3
ci <- .95
a <- 1-a/2
k <- 109
n <- 110
Cu <- x + qt(a,k)*s/sqrt(n)
Cl <- x - qt(a,k)*s/sqrt(n)
x <- 76.7
s <- 12.3
ci <- .95
a <- 1-ci/2
k <- 109
n <- 110
Cu <- x + qt(a,k)*s/sqrt(n)
Cl <- x - qt(a,k)*s/sqrt(n)
x <- 76.7
s <- 12.3
ci <- .95
a <- 1-0.95
k <- 109
n <- 110
Cu <- x + qt(1-a/2,k)*s/sqrt(n)
Cl <- x - qt(1-a/2,k)*s/sqrt(n)
pnorm(.41667)
1-pnotm(.4167)
1-pnorm(.4167)
1-pnorm(2.771)
1-pnorm(.7217)
qt(0.97,48)
qt(.93,81)
qt(0.87,149)
x <- 3.2
n <- 100
s <- 0.2
a <- 1-0.97
df <- 100-1
right <- x + qt(1-a/2, df)*s/sqrt(n)
left <- x - qt(1-a/2, df)*s/sqrt(n)
qt(1-a/2, df)*s/sqrt(n)
qt(1-a/2, df)*s/sqrt(n)
qt(1-0.05/(2*3), 200-3-1)
library(glmnet)
##model.matrix automatically transform categorical variables into dummy codes, which is needed as the glmnet function cannot handle categorical variables
x<-model.matrix(mpg~.,mtcars)[,-1]
y<-mtcars$mpg
View(x)
pairs(x, lower.panel=NULL, main="Scatterplots of Predictors")
##alpha=0 for ridge, alpha=1 for LASSO
##threshold value should be very small if multicollinearity is present. see what happens if thresh was set to a larger value
##we know theoretically the coeffs should be the same as lm when lambda is 0
ridge.r<-glmnet(x,y,alpha=0, lambda=0, thresh = 1e-14)
coefficients(ridge.r)
##MLR
result<-lm(mpg~.,mtcars)
summary(result)
ridge.r<-glmnet(x,y,alpha=0, lambda=0, thresh = 1e-14)
coefficients(ridge.r)
##alpha=0 for ridge, alpha=1 for LASSO
##threshold value should be very small if multicollinearity is present. see what happens if thresh was set to a larger value
##we know theoretically the coeffs should be the same as lm when lambda is 0
ridge.r<-glmnet(x,y,alpha=0, lambda=0, thresh = 1e-4)
ridge.r<-glmnet(x,y,alpha=0, lambda=0, thresh = 1e-4)
coefficients(ridge.r)
x<-model.matrix(mpg~.,mtcars)[,-1]
y<-mtcars$mpg
##Note some predictors are highly correlated with each other.
pairs(x, lower.panel=NULL, main="Scatterplots of Predictors")
##alpha=0 for ridge, alpha=1 for LASSO
##threshold value should be very small if multicollinearity is present. see what happens if thresh was set to a larger value
##we know theoretically the coeffs should be the same as lm when lambda is 0
ridge.r<-glmnet(x,y,alpha=0, lambda=0, thresh = 1e-14)
coefficients(ridge.r)
result<-lm(mpg~.,mtcars)
summary(result)
set.seed(12)
train<-sample(1:nrow(x), nrow(x)/2)
test<-(-train)
y.test<-y[test]
set.seed(12)
cv.out<-cv.glmnet(x[train,],y[train],alpha=0)
bestlam<-cv.out$lambda.min
bestlam
plot(cv.out)
ridge.mod<-glmnet(x[train,],y[train],alpha=0,lambda=bestlam, thresh = 1e-14)
ridge.pred<-predict(ridge.mod,s=bestlam,newx=x[test,])
mean((ridge.pred-y.test)^2)
ridge.mod.0<-glmnet(x[train,],y[train],alpha=0,lambda=0, thresh = 1e-14)
ridge.pred.0<-predict(ridge.mod.0,newx=x[test,])
mean((ridge.pred.0-y.test)^2)
out.ridge<-glmnet(x,y,alpha=0,lambda=bestlam,thresh = 1e-14)
out.ols<-glmnet(x,y,alpha=0, lambda=0, thresh = 1e-14)
cbind(coefficients(out.ridge), coefficients(out.ols))
grid<-10^seq(10,-2,length=100)
out.all<-glmnet(x,y,alpha=0,lambda=grid,thresh = 1e-14)
plot(out.all, xvar = "lambda")
abline(v=log(bestlam), lty=2)
legend("bottomright", lwd = 1, col = 1:6, legend = colnames(x), cex = .7)
names(mtcars)
?mtcars
pr.out<-prcomp(mtcars[,c(-8,-9)], scale=TRUE)
pr.out$center
pr.out$scale
apply(mtcars[,c(-8,-9)], 2, mean)
apply(mtcars[,c(-8,-9)], 2, sd)
pr.out$rotation
pr.out$sdev
pr.var<-pr.out$sdev^2
pr.var
pve<-pr.var/sum(pr.var)
pve
biplot(pr.out, scale=0)
plot(pve, ylim=c(0,1))
plot(pve, xlab="Principal Component", ylab="Proportion of Variance Explained", main="Scree Plot", ylim=c(0,1),type='b')
plot(cumsum(pve), xlab="Principal Component", ylab="Cumulative Proportion of Variance Explained", main="Cumulative Proportion", ylim=c(0,1),type='b')
names(mtcars)
?mtcars
x<-model.matrix(mpg~.,mtcars)[,-1]
y<-mtcars$mpg
setwd("~/MSDS/Spring 2021/Linear Models For Data Science/melbourne-housing")
shiny::runApp()
runApp()
runApp()
runApp()
library(tidyverse)
library(data.table)
library(dplyr)
library(lubridate) # Datetime
###you need to read in your NA's, leaving stringasfactors as false, but true would save you some work later
melbourne <- read.csv("melb_data_raw.csv", stringsAsFactors = FALSE, na.strings = c(""," ","NA","NULL"), header=TRUE)
# view if any null columns
colSums(is.na(melbourne))
roomsAndTypeGrouped <- melbourne %>%
group_by(Rooms, Type) %>%
summarise(medianArea = median(BuildingArea, na.rm=TRUE))
library(tidyverse)
library(data.table)
library(dplyr)
library(lubridate) # Datetime
###you need to read in your NA's, leaving stringasfactors as false, but true would save you some work later
melbourne <- read.csv("melb_data_raw.csv", stringsAsFactors = FALSE, na.strings = c(""," ","NA","NULL"), header=TRUE)
# view if any null columns
colSums(is.na(melbourne))
# =================================================================================================================
# BuildingArea: 6417 NA Values - fillna with median building area for type of building with same number of bedrooms
# YearBuilt: 5344 NA Values - fillna with the median year built for type of building in the respective suburb
# REASONING: Filling NA values strictly by suburb or number of bedrooms would introduce flawed assumptions,
#            an old suburb that used to consist of mainly houses may be be home to new builds that would
#            consist of townhomes and apartments, so we need to consider building type during the imputations.
# Car: 62 NA Values - fillna with with mode of Car since it's only 62 instances
# =================================================================================================================
# getting the median building area by number of rooms and type of building
roomsAndTypeGrouped <- melbourne %>%
group_by(Rooms, Type) %>%
summarise(medianArea = median(BuildingArea, na.rm=TRUE))
# getting the median year built by suburb and type of building
suburbAndTypeGrouped <- melbourne %>%
group_by(Suburb, Type) %>%
summarise(medianYear = median(YearBuilt, na.rm=TRUE))
# getting the median number of car spots per building type to fill the 62 null values with
TypeGrouped <- melbourne %>%
group_by(Type) %>%
summarise(medianCar = median(Car, na.rm=TRUE))
# After grouping median year built by suburb and type of building, there are still 80 NA values, so I'll fill those by median year by building type
TypeGroupForRemainingNAyears <- melbourne %>%
group_by(Type) %>%
summarise(medianYearType = median(YearBuilt, na.rm=TRUE))
# filling in the blank council areas
suburbAndCouncilGrouped <- melbourne %>%
group_by(Suburb, CouncilArea)
# median for 4 rooms of type U = 171.5, so I'm going to double it for the null value at 8 rooms of type u.
roomsAndTypeGrouped$medianArea[19]=394.45
# median for 5 rooms of type h = 260, so I'm doubling it for the null value at 10 rooms of type h
roomsAndTypeGrouped$medianArea[20]=520
# merging all of the grouped datasets into a copy of the melbourne data, and then filling null values with its respective median value
testMerge <- merge(melbourne, roomsAndTypeGrouped, by=c("Rooms", "Type"))
testMerge$BuildingArea <- ifelse(is.na(testMerge$BuildingArea), testMerge$medianArea, testMerge$BuildingArea)
testMerge <- merge(testMerge, suburbAndTypeGrouped, by=c("Suburb", "Type"))
testMerge$YearBuilt <- ifelse(is.na(testMerge$YearBuilt), testMerge$medianYear, testMerge$YearBuilt)
testMerge <- merge(testMerge, TypeGrouped, by="Type")
testMerge$Car <- ifelse(is.na(testMerge$Car), testMerge$medianCar, testMerge$Car)
testMerge <- merge(testMerge, TypeGroupForRemainingNAyears, by="Type")
testMerge$YearBuilt <- ifelse(is.na(testMerge$YearBuilt), testMerge$medianYearType, testMerge$YearBuilt)
councilSuburbs <- testMerge[!duplicated(testMerge[,c("Suburb", "CouncilArea")]),]
councilSuburbs <- subset(councilSuburbs, select = c( Suburb, CouncilArea))
councilSuburbs <- na.omit(councilSuburbs)
councilSuburbs <- councilSuburbs[!duplicated(councilSuburbs[,c("Suburb", "CouncilArea")]),]
councilSuburbs <- councilSuburbs[!duplicated(councilSuburbs$Suburb), ]
testMerge <- merge(testMerge, councilSuburbs, by="Suburb")
testMerge$CouncilArea <- ifelse(is.na(testMerge$CouncilArea.x), testMerge$CouncilArea.y, testMerge$CouncilArea.x)
# drop the median columns. Address, seller, and method of sale don't have much to do with the value of a house
testMerge <- subset(testMerge, select = -c(Address, medianArea, medianYear, medianCar, medianYearType, Bedroom2, CouncilArea.x, CouncilArea.y))
testMerge <- distinct(testMerge)
melbourne <- testMerge
factor.list.sub <- c("CouncilArea","Postcode","Regionname","SellerG","Suburb")
for (f in factor.list.sub) {
x <- paste("agg_",f, sep="")
eval(call("<-", as.name(x), aggregate(melbourne[,names(melbourne)%in% f], by = list(melbourne[,names(melbourne)%in% f]), NROW)))
}
##anything less than 100 frequency in councilarea, change to other
consolidate <- 100
for (i in 1:NROW(agg_CouncilArea)){
if (agg_CouncilArea[i,2] <= consolidate){
melbourne$CouncilArea <- as.character(melbourne$CouncilArea)
melbourne$CouncilArea[melbourne$CouncilArea == agg_CouncilArea[i,1] & !is.na(melbourne$CouncilArea)] <- "Other"
melbourne$CouncilArea <- as.factor(melbourne$CouncilArea)
}
}
##anything less than 25 frequency in post code, change to other
consolidate <- 25
for (i in 1:NROW(agg_Postcode)){
if (agg_Postcode[i,2] <= consolidate){
melbourne$Postcode <- as.character(melbourne$Postcode)
melbourne$Postcode[melbourne$Postcode == agg_Postcode[i,1] & !is.na(melbourne$Postcode)] <- "Other"
melbourne$Postcode <- as.factor(melbourne$Postcode)
}
}
##anything less than 20 frequency in seller, change to other
consolidate <- 20
for (i in 1:NROW(agg_SellerG)){
if (agg_SellerG[i,2] <= consolidate){
melbourne$SellerG <- as.character(melbourne$SellerG)
melbourne$SellerG[melbourne$SellerG == agg_SellerG[i,1] & !is.na(melbourne$SellerG)] <- "Other"
melbourne$SellerG <- as.factor(melbourne$SellerG)
}
}
##anything less than 20 frequency in suburb, change to other
consolidate <- 20
for (i in 1:NROW(agg_Suburb)){
if (agg_Suburb[i,2] <= consolidate){
melbourne$Suburb <- as.character(melbourne$Suburb)
melbourne$Suburb[melbourne$Suburb == agg_Suburb[i,1] & !is.na(melbourne$Suburb)] <- "Other"
melbourne$Suburb <- as.factor(melbourne$Suburb)
}
}
# view if any null columns
colSums(is.na(melbourne))
melbourne$YearBuilt<-round(as.numeric(melbourne$YearBuilt), 0)
# ===============================================================================
# There are multiple date formats in the date column {17/09/2016, 4/03/2017, etc.}
# We can standardize the date formatting with the lubridate package
# ===============================================================================
mdy <- mdy(melbourne$Date)
dmy <- dmy(melbourne$Date)
mdy[is.na(mdy)] <- dmy[is.na(mdy)]
melbourne$Date <- mdy
melbourne$Month <- month(melbourne$Date)
melbourne$Year <- year(melbourne$Date)
# arrange by date for time series analysis purposes
melbourne <- arrange(melbourne, Date)
melbourneMassiveOutliersRemoved <- melbourne[!melbourne$BuildingArea > quantile(melbourne$BuildingArea, probs = c(.98)),]
melbourneMassiveOutliersRemoved <- melbourneMassiveOutliersRemoved[!melbourneMassiveOutliersRemoved$Landsize > quantile(melbourne$Landsize, probs = c(.98)),]
melbourneMassiveOutliersRemoved %>% filter(YearBuilt > 1800)
melbourneMassiveOutliersRemoved <- melbourneMassiveOutliersRemoved %>% filter(YearBuilt > 1750)
View(melbourneMassiveOutliersRemoved)
write.csv(melbourneMassiveOutliersRemoved, file="./melbourne_cleaned.csv")
runApp()
runApp()
runApp()
library(tidyverse)
library(data.table)
library(dplyr)
library(lubridate) # Datetime
###you need to read in your NA's, leaving stringasfactors as false, but true would save you some work later
melbourne <- read.csv("melb_data_raw.csv", stringsAsFactors = FALSE, na.strings = c(""," ","NA","NULL"), header=TRUE)
# view if any null columns
colSums(is.na(melbourne))
# =================================================================================================================
# BuildingArea: 6417 NA Values - fillna with median building area for type of building with same number of bedrooms
# YearBuilt: 5344 NA Values - fillna with the median year built for type of building in the respective suburb
# REASONING: Filling NA values strictly by suburb or number of bedrooms would introduce flawed assumptions,
#            an old suburb that used to consist of mainly houses may be be home to new builds that would
#            consist of townhomes and apartments, so we need to consider building type during the imputations.
# Car: 62 NA Values - fillna with with mode of Car since it's only 62 instances
# =================================================================================================================
# getting the median building area by number of rooms and type of building
roomsAndTypeGrouped <- melbourne %>%
group_by(Rooms, Type) %>%
summarise(medianArea = median(BuildingArea, na.rm=TRUE))
# getting the median year built by suburb and type of building
suburbAndTypeGrouped <- melbourne %>%
group_by(Suburb, Type) %>%
summarise(medianYear = median(YearBuilt, na.rm=TRUE))
# getting the median number of car spots per building type to fill the 62 null values with
TypeGrouped <- melbourne %>%
group_by(Type) %>%
summarise(medianCar = median(Car, na.rm=TRUE))
# After grouping median year built by suburb and type of building, there are still 80 NA values, so I'll fill those by median year by building type
TypeGroupForRemainingNAyears <- melbourne %>%
group_by(Type) %>%
summarise(medianYearType = median(YearBuilt, na.rm=TRUE))
# filling in the blank council areas
suburbAndCouncilGrouped <- melbourne %>%
group_by(Suburb, CouncilArea)
# median for 4 rooms of type U = 171.5, so I'm going to double it for the null value at 8 rooms of type u.
roomsAndTypeGrouped$medianArea[19]=394.45
# median for 5 rooms of type h = 260, so I'm doubling it for the null value at 10 rooms of type h
roomsAndTypeGrouped$medianArea[20]=520
# merging all of the grouped datasets into a copy of the melbourne data, and then filling null values with its respective median value
testMerge <- merge(melbourne, roomsAndTypeGrouped, by=c("Rooms", "Type"))
testMerge$BuildingArea <- ifelse(is.na(testMerge$BuildingArea), testMerge$medianArea, testMerge$BuildingArea)
testMerge <- merge(testMerge, suburbAndTypeGrouped, by=c("Suburb", "Type"))
testMerge$YearBuilt <- ifelse(is.na(testMerge$YearBuilt), testMerge$medianYear, testMerge$YearBuilt)
testMerge <- merge(testMerge, TypeGrouped, by="Type")
testMerge$Car <- ifelse(is.na(testMerge$Car), testMerge$medianCar, testMerge$Car)
testMerge <- merge(testMerge, TypeGroupForRemainingNAyears, by="Type")
testMerge$YearBuilt <- ifelse(is.na(testMerge$YearBuilt), testMerge$medianYearType, testMerge$YearBuilt)
councilSuburbs <- testMerge[!duplicated(testMerge[,c("Suburb", "CouncilArea")]),]
councilSuburbs <- subset(councilSuburbs, select = c( Suburb, CouncilArea))
councilSuburbs <- na.omit(councilSuburbs)
councilSuburbs <- councilSuburbs[!duplicated(councilSuburbs[,c("Suburb", "CouncilArea")]),]
councilSuburbs <- councilSuburbs[!duplicated(councilSuburbs$Suburb), ]
testMerge <- merge(testMerge, councilSuburbs, by="Suburb")
testMerge$CouncilArea <- ifelse(is.na(testMerge$CouncilArea.x), testMerge$CouncilArea.y, testMerge$CouncilArea.x)
# drop the median columns. Address, seller, and method of sale don't have much to do with the value of a house
testMerge <- subset(testMerge, select = -c(Address, medianArea, medianYear, medianCar, medianYearType, Bedroom2, CouncilArea.x, CouncilArea.y))
testMerge <- distinct(testMerge)
melbourne <- testMerge
factor.list.sub <- c("CouncilArea","Postcode","Regionname","SellerG","Suburb")
for (f in factor.list.sub) {
x <- paste("agg_",f, sep="")
eval(call("<-", as.name(x), aggregate(melbourne[,names(melbourne)%in% f], by = list(melbourne[,names(melbourne)%in% f]), NROW)))
}
##anything less than 100 frequency in councilarea, change to other
consolidate <- 100
for (i in 1:NROW(agg_CouncilArea)){
if (agg_CouncilArea[i,2] <= consolidate){
melbourne$CouncilArea <- as.character(melbourne$CouncilArea)
melbourne$CouncilArea[melbourne$CouncilArea == agg_CouncilArea[i,1] & !is.na(melbourne$CouncilArea)] <- "Other"
melbourne$CouncilArea <- as.factor(melbourne$CouncilArea)
}
}
##anything less than 25 frequency in post code, change to other
consolidate <- 25
for (i in 1:NROW(agg_Postcode)){
if (agg_Postcode[i,2] <= consolidate){
melbourne$Postcode <- as.character(melbourne$Postcode)
melbourne$Postcode[melbourne$Postcode == agg_Postcode[i,1] & !is.na(melbourne$Postcode)] <- "Other"
melbourne$Postcode <- as.factor(melbourne$Postcode)
}
}
##anything less than 20 frequency in seller, change to other
consolidate <- 20
for (i in 1:NROW(agg_SellerG)){
if (agg_SellerG[i,2] <= consolidate){
melbourne$SellerG <- as.character(melbourne$SellerG)
melbourne$SellerG[melbourne$SellerG == agg_SellerG[i,1] & !is.na(melbourne$SellerG)] <- "Other"
melbourne$SellerG <- as.factor(melbourne$SellerG)
}
}
##anything less than 20 frequency in suburb, change to other
consolidate <- 20
for (i in 1:NROW(agg_Suburb)){
if (agg_Suburb[i,2] <= consolidate){
melbourne$Suburb <- as.character(melbourne$Suburb)
melbourne$Suburb[melbourne$Suburb == agg_Suburb[i,1] & !is.na(melbourne$Suburb)] <- "Other"
melbourne$Suburb <- as.factor(melbourne$Suburb)
}
}
# view if any null columns
colSums(is.na(melbourne))
melbourne$YearBuilt<-round(as.numeric(melbourne$YearBuilt), 0)
# ===============================================================================
# There are multiple date formats in the date column {17/09/2016, 4/03/2017, etc.}
# We can standardize the date formatting with the lubridate package
# ===============================================================================
mdy <- mdy(melbourne$Date)
dmy <- dmy(melbourne$Date)
mdy[is.na(mdy)] <- dmy[is.na(mdy)]
melbourne$Date <- mdy
melbourne$Month <- month(melbourne$Date)
melbourne$Year <- year(melbourne$Date)
# arrange by date for time series analysis purposes
melbourne <- arrange(melbourne, Date)
melbourneMassiveOutliersRemoved <- melbourne[!melbourne$BuildingArea > quantile(melbourne$BuildingArea, probs = c(.98)),]
melbourneMassiveOutliersRemoved <- melbourneMassiveOutliersRemoved[!melbourneMassiveOutliersRemoved$Landsize > quantile(melbourne$Landsize, probs = c(.98)),]
melbourneMassiveOutliersRemoved <- melbourneMassiveOutliersRemoved %>% filter(YearBuilt > 1750)
View(melbourneMassiveOutliersRemoved)
library(tidyverse)
library(data.table)
library(dplyr)
library(lubridate) # Datetime
###you need to read in your NA's, leaving stringasfactors as false, but true would save you some work later
melbourne <- read.csv("melb_data_raw.csv", stringsAsFactors = FALSE, na.strings = c(""," ","NA","NULL"), header=TRUE)
# view if any null columns
colSums(is.na(melbourne))
# =================================================================================================================
# BuildingArea: 6417 NA Values - fillna with median building area for type of building with same number of bedrooms
# YearBuilt: 5344 NA Values - fillna with the median year built for type of building in the respective suburb
# REASONING: Filling NA values strictly by suburb or number of bedrooms would introduce flawed assumptions,
#            an old suburb that used to consist of mainly houses may be be home to new builds that would
#            consist of townhomes and apartments, so we need to consider building type during the imputations.
# Car: 62 NA Values - fillna with with mode of Car since it's only 62 instances
# =================================================================================================================
# getting the median building area by number of rooms and type of building
roomsAndTypeGrouped <- melbourne %>%
group_by(Rooms, Type) %>%
summarise(medianArea = median(BuildingArea, na.rm=TRUE))
# getting the median year built by suburb and type of building
suburbAndTypeGrouped <- melbourne %>%
group_by(Suburb, Type) %>%
summarise(medianYear = median(YearBuilt, na.rm=TRUE))
# getting the median number of car spots per building type to fill the 62 null values with
TypeGrouped <- melbourne %>%
group_by(Type) %>%
summarise(medianCar = median(Car, na.rm=TRUE))
# After grouping median year built by suburb and type of building, there are still 80 NA values, so I'll fill those by median year by building type
TypeGroupForRemainingNAyears <- melbourne %>%
group_by(Type) %>%
summarise(medianYearType = median(YearBuilt, na.rm=TRUE))
# filling in the blank council areas
suburbAndCouncilGrouped <- melbourne %>%
group_by(Suburb, CouncilArea)
# median for 4 rooms of type U = 171.5, so I'm going to double it for the null value at 8 rooms of type u.
roomsAndTypeGrouped$medianArea[19]=394.45
# median for 5 rooms of type h = 260, so I'm doubling it for the null value at 10 rooms of type h
roomsAndTypeGrouped$medianArea[20]=520
# merging all of the grouped datasets into a copy of the melbourne data, and then filling null values with its respective median value
testMerge <- merge(melbourne, roomsAndTypeGrouped, by=c("Rooms", "Type"))
testMerge$BuildingArea <- ifelse(is.na(testMerge$BuildingArea), testMerge$medianArea, testMerge$BuildingArea)
testMerge <- merge(testMerge, suburbAndTypeGrouped, by=c("Suburb", "Type"))
testMerge$YearBuilt <- ifelse(is.na(testMerge$YearBuilt), testMerge$medianYear, testMerge$YearBuilt)
testMerge <- merge(testMerge, TypeGrouped, by="Type")
testMerge$Car <- ifelse(is.na(testMerge$Car), testMerge$medianCar, testMerge$Car)
testMerge <- merge(testMerge, TypeGroupForRemainingNAyears, by="Type")
testMerge$YearBuilt <- ifelse(is.na(testMerge$YearBuilt), testMerge$medianYearType, testMerge$YearBuilt)
councilSuburbs <- testMerge[!duplicated(testMerge[,c("Suburb", "CouncilArea")]),]
councilSuburbs <- subset(councilSuburbs, select = c( Suburb, CouncilArea))
councilSuburbs <- na.omit(councilSuburbs)
councilSuburbs <- councilSuburbs[!duplicated(councilSuburbs[,c("Suburb", "CouncilArea")]),]
councilSuburbs <- councilSuburbs[!duplicated(councilSuburbs$Suburb), ]
testMerge <- merge(testMerge, councilSuburbs, by="Suburb")
testMerge$CouncilArea <- ifelse(is.na(testMerge$CouncilArea.x), testMerge$CouncilArea.y, testMerge$CouncilArea.x)
# drop the median columns. Address, seller, and method of sale don't have much to do with the value of a house
testMerge <- subset(testMerge, select = -c(Address, medianArea, medianYear, medianCar, medianYearType, Bedroom2, CouncilArea.x, CouncilArea.y))
testMerge <- distinct(testMerge)
melbourne <- testMerge
factor.list.sub <- c("CouncilArea","Postcode","Regionname","SellerG","Suburb")
for (f in factor.list.sub) {
x <- paste("agg_",f, sep="")
eval(call("<-", as.name(x), aggregate(melbourne[,names(melbourne)%in% f], by = list(melbourne[,names(melbourne)%in% f]), NROW)))
}
##anything less than 100 frequency in councilarea, change to other
consolidate <- 100
for (i in 1:NROW(agg_CouncilArea)){
if (agg_CouncilArea[i,2] <= consolidate){
melbourne$CouncilArea <- as.character(melbourne$CouncilArea)
melbourne$CouncilArea[melbourne$CouncilArea == agg_CouncilArea[i,1] & !is.na(melbourne$CouncilArea)] <- "Other"
melbourne$CouncilArea <- as.factor(melbourne$CouncilArea)
}
}
##anything less than 25 frequency in post code, change to other
consolidate <- 25
for (i in 1:NROW(agg_Postcode)){
if (agg_Postcode[i,2] <= consolidate){
melbourne$Postcode <- as.character(melbourne$Postcode)
melbourne$Postcode[melbourne$Postcode == agg_Postcode[i,1] & !is.na(melbourne$Postcode)] <- "Other"
melbourne$Postcode <- as.factor(melbourne$Postcode)
}
}
##anything less than 20 frequency in seller, change to other
consolidate <- 20
for (i in 1:NROW(agg_SellerG)){
if (agg_SellerG[i,2] <= consolidate){
melbourne$SellerG <- as.character(melbourne$SellerG)
melbourne$SellerG[melbourne$SellerG == agg_SellerG[i,1] & !is.na(melbourne$SellerG)] <- "Other"
melbourne$SellerG <- as.factor(melbourne$SellerG)
}
}
##anything less than 20 frequency in suburb, change to other
consolidate <- 20
for (i in 1:NROW(agg_Suburb)){
if (agg_Suburb[i,2] <= consolidate){
melbourne$Suburb <- as.character(melbourne$Suburb)
melbourne$Suburb[melbourne$Suburb == agg_Suburb[i,1] & !is.na(melbourne$Suburb)] <- "Other"
melbourne$Suburb <- as.factor(melbourne$Suburb)
}
}
# view if any null columns
colSums(is.na(melbourne))
melbourne$YearBuilt<-round(as.numeric(melbourne$YearBuilt), 0)
# ===============================================================================
# There are multiple date formats in the date column {17/09/2016, 4/03/2017, etc.}
# We can standardize the date formatting with the lubridate package
# ===============================================================================
mdy <- mdy(melbourne$Date)
dmy <- dmy(melbourne$Date)
mdy[is.na(mdy)] <- dmy[is.na(mdy)]
melbourne$Date <- mdy
melbourne$Month <- month(melbourne$Date)
melbourne$Year <- year(melbourne$Date)
# arrange by date for time series analysis purposes
melbourne <- arrange(melbourne, Date)
melbourneMassiveOutliersRemoved <- melbourne[!melbourne$BuildingArea > quantile(melbourne$BuildingArea, probs = c(.98)),]
melbourneMassiveOutliersRemoved <- melbourneMassiveOutliersRemoved[!melbourneMassiveOutliersRemoved$Landsize > quantile(melbourne$Landsize, probs = c(.98)),]
melbourneMassiveOutliersRemoved <- melbourneMassiveOutliersRemoved %>% filter(YearBuilt > 1750)
View(melbourneMassiveOutliersRemoved)
melbourneMassiveOutliersRemoved[10789]=900000
View(melbourneMassiveOutliersRemoved)
melbourneMassiveOutliersRemoved$Price[10789]=900000
View(melbourneMassiveOutliersRemoved)
# export to a cleaned csv file
write.csv(melbourneMassiveOutliersRemoved, file="./melbourne_cleaned.csv")
runApp()
>>>>>>> 3f19008d7d660efd0e80ca206145652c71b6f3f2
runApp()
runApp()
'%notin%' <- Negate('%in%')
quant <- c("Price","Rooms","Bathroom","Distance","Car","Landsize","BuildingArea","YearBuilt") %notin% "Price"
quant
quant <- c("Price","Rooms","Bathroom","Distance","Car","Landsize","BuildingArea","YearBuilt")
quant <- quant[quant %notin% "Price"]
ceiling(7/2)
runApp()
runApp()
install.packages("shinyMatrix")
runApp()
runApp()
matrix(data = rep.int(1,length(input$quantchoose5) + 1), nrow = length(input$quantchoose5) + 1, ncol = 1,dimnames = list(c(input$quantchoose4, input$quantchoose5),c("User Transformation")))
matrix(data = rep.int(1,5 + 1), nrow = 5 + 1, ncol = 1,dimnames = list(c(, "name2"),c("User Transformation")))
matrix(data = rep.int(1,5 + 1), nrow = 5 + 1, ncol = 1,dimnames = list(c("name", "name2"),c("User Transformation")))
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
library(corrplot)
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
install.packages("conquer")
library(conquer)
install.packages("Rcpp")
install.packages("Rcpp")
library(conquer)
library(Rcpp)
install.packages("Rcpp")
detach(package:Rcpp, unload = TRUE)
